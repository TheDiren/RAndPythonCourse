---
title: "Data Science in Environmental Science and Oceanography with R and Python"
subtitle: "Course Notes"
authors: 
  - Dana Ransby
  - Kathrin Riemann-Campe
  - Maren Rebke
  - Diren Senger
  - (Alfred-Wegener-Institut Helmholtz Zentrum für Polar- und Meeresforschung)
date: "`r Sys.Date()`"
self-contained: true
editor: visual
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 2
    number-sections: true
    code-fold: false
    link-citations: true
    description: "Interactive course notes for workshop of Informatica Feminale 25"
    cover-image: images/cover.png
    self-contained: true
    include-in-header: 
      - text: |
          <meta name="sharing" content="no">
    lib-dir: book_assets
---

# About

This guide was created for the course "Data Science in Environmental Science and Oceanography with R and Python" at the Informatica Feminale 2025.

# Agenda

## Agenda - Day 1: PANGAEA and R & Python basics

| **Aug 20th** | Topic | Presenter |
|------------------|------------------------------------|------------------|
| 10:00 | Round of introductions (20 min) | all including participants |
| 10:00 | Intro PANGAEA, data repos (20 min) | DR |
| 10:20 | How to find and use data from PANGAEA (15 mins) | KRC |
| 10:35 | Quiz (10 min) | KRC |
| 10:45 | How to download datasets (10 min) | KRC |
| 10:55 | Questions I (10 min) | KRC & DR |
| 11:05 | **break** |  |
| 11:15 | Intro to PANGAEA packages and tokens (20-25 min) | DR |
| 11:35 | Questions II (10min) | DR & KRC |
|  |  |  |
| 11:45 | **Lunch break** |  |
|  |  |  |
| 02:00 | basics R and python | DS |
| 04:30 | end of day 1 |  |

## Agenda - Day 2: Getting data from PANGAEA und Data Cleaning

| **Aug 21st** | Topic | Presenter |
|------------------|------------------------------------|------------------|
| 09:00 | Downloading and manipulating PANGAEA data in R - in brief | DR |
| 09:45 | **Minibreak** |  |
| 09:50 | Downloading and manipulating PANGAEA data in Python (100 min including **bio break** after 45 min) | KRC |
| 12:30 | **Lunch break** |  |
| 02:00 | Data Cleaning in python | KRC |
| 03:40 | Data Cleaning in R | DS |
| 04:30 | end of day 2 |  |

## Agenda - Day 3: Plotting und Statistics

| **Aug 22nd** | Topic | Presenter |
|------------------|------------------------------------|------------------|
| 09:00 | Intro and Cleaning of Penguin data set, Plotting & Statistics | DS & MR |
| 12:30 | **Lunch break** |  |
| 02:00 | Markdown & time for open Questions | all |
| 04:30 | end of day 3 |  |

# Before the course

## Installation Notes

::: panel-tabset
### R

If you haven't installed R and RStudio yet, use following instructions for the installation:

1.  Install R:

Installation on Windows and Mac <https://www.dataquest.io/blog/installing-r-on-your-computer/> For Linux <https://cran.r-project.org/doc/FAQ/R-FAQ.html#How-can-R-be-installed-_0028Unix_002dlike_0029>

2.  Install the free RStudio Desktop Version: https://www.rstudio.com/products/rstudio/#Desktop

3.  Do you know how you can install new R packages? You can read about it here: <https://thedatacommunity.org/2017/09/17/installing-loading-unloading-and-removing-r-packages-in-rstudio/>

In this script, we make use of following packages:

-   pangaear
-   dplyr
-   tidyr
-   stringr
-   lubridate
-   httr
-   worrms
-   knitr
-   magrittr
-   car
-   palmerpenguins
-   reshape
-   ggplot2
-   (reticulate)

### Python

Very many integrated development environment (IDE) software programs exist for Python. For this beginners course, we recommend the free and open source Python IDE called [Thonny](https://thonny.org/).

1.  Install Python:\
    [Thonny](https://thonny.org/) is available for Windows, Mac and Linux. Just download the suitable executable installation file for your computer and start the installation. The basic set up of Python is done. When you open [Thonny](https://thonny.org/) for the first time, you will see the default set up of windows with a *code editor* on the upper left side, a *shell* on the lower left side and an *assistant* on the right hand side: ![Thonny default set up](images/thonny_default_setup.png){width="800"}

2.  Install additional Python packages:\
    During our course, we will use several additional packages. All can be installed **either** via the package installer PIP.\
    Example: Write the following code in the shell to install PANGAEApy.\

```{python, eval = FALSE}
!pip install pangaeapy
```

**Or** click in the upper left hand corner of [Thonny](https://thonny.org/) on *Tools* and select *Manage packages …*. Search *jupyter* on PyPI and click on the *jupyter* search result to start the installation.

The following packages are needed for this course:\
- jupyter\
- pangaeapy\
- numpy\
- pandas\
- re\
- os\
- datetime\
- ipdb\
- requests\
- LatLon23\
- difflib\
- collections\
- matplotlib\
- plotly
:::

## Programming Environments

::: panel-tabset
### R

For R, we recommend RStudio.

#### Creating a new project

In many statistics classes they teach you, that you should set a working directory:

```{r eval=F}
setwd("~/Documents/")
```

It can be helpful to create a project instead. All files within the project's directory will automatically have the correct working directory. In this way you can create new files and start coding easily.

1.  Click File -\> New Project... Even when you choose "Existing Directory" you will still be able to create a new directory ![Creating a Project, Step 1](images/project1.png)
2.  Enter the diretory path straight away, or click on browse. ![Creating a Project, Step 2](images/project2.png)
3.  Choose an existing directory or create a new one ![Creating a Project, Step 3](images/project3.png)

#### RStudio screen

-   In the upper left hand corner you have the code editor. This is where you can type your scripts.
-   In the bottom left hand corner you have the console. Here you will see the results of all commands you are running.
-   In the upper right hand corner you can see all objects you created, e.g. data frames, functions, strings, ...
-   In the bottom left hand corner you will be able to see the files in your project, your plots and more information e.g. about functions ![RStudio screen](images/rstudio.png)

You can use "Ctrl" followed by a number to jump to a specific window. If you want to get into the terminal use "Shift+Alt+t" or "Shift+Alt+m". You can find an overview of all short cuts using "Shift+Alt+k". ![RStudio screen](images/rstudioNumbers.png)

#### R Workflow

-   You type your scripts in the code editor, so that you can save them.
-   If you want to run the whole script, you can click on 'Source' at the tope of the code editor or press "Ctrl + Alt + R". (Shortcuts might differ depending on your system.)
-   Use "Ctrl + Alt + B/E" to run from the beginning to the current line or from the current line to the end.
-   If you want to run a single line, you can click on 'Run' or press "Control + Enter"
-   If you want to run a few lines, highlight the lines you want to run and use 'Run'/ "Control + Enter"
-   If you want to use Autocomplete, you can press "Control + Space"
-   If you want to read about an existing method, you can type "?\<Name of the method\>" to get to the documentation

### Python

#### Save your code in a script or notebook

Python code is saved **either** in scripts with *.py* ending **or** in so called [Jupyter Notebook](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html)s with *.ipynb* ending. There is no difference in the python code itself only in the way the code is executed.

-   Files with **.py** ending need to be executed in a *shell* or *terminal*, somewhere you type the command to execute your script. If you want to know more about the differences between a shell and a terminal, have a look at [GeeksforGeeks](https://www.geeksforgeeks.org/operating-systems/difference-between-terminal-console-shell-and-command-line/).

-   Files with **.ipynb** ending consist of individual cells which can be executed directly in the [Jupyter Notebook](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html).

-   Note: If you open a Jupyter Notebook in an editor, you will see that the python code is mixed with additional code to interprete each notebook cell. You can convert *.py* files to *.ipynb* files an vice versa using a command line tool in the *shell* as described in the [nbconvert documentation](https://nbconvert.readthedocs.io/en/latest/usage.html#convert-script).

In this course we will work with [Jupyter Notebook](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html). To open a *Jupyter environment* write in the *shell* window of [Thonny](https://thonny.org/):\
`!jupyter notebook`

After pressing *enter*, a browser window will open to show you your *Home directory*. ![Jupyter home](images/example_jupyter_home.png){width="800"} Double click on your Jupyter Notebook of choice to open it or open a new one with the *File* button, select *new* and *Notebook*. Select the suggested Kernel and start scripting. ![New Notebook](images/example_notebook_new.png){width="75%"}\
Type anything you want, e.g. print('Hello World'), into the cell and execute it by clicking on the button with the single triangle.
:::

## Data types

::: panel-tabset
### R

#### Character

```{r}
firstname <- "Pipi"
surname <- "Langstrumpf"
name <- paste(firstname, surname)
name
```

#### Numeric

```{r}
a <- 1
b <- 2
c <- a + b
c
d <- b*c/a
d
e <- d^2
e
f <- as.integer(3.14)
f
```

#### Logical

```{r}
a <- TRUE
b <- FALSE

# or
a|b

# and
a&b

# not
!a

4 == 5

4 < 5
4>=4

is.na

as.numeric(a)
```

#### && and \|\|

```{r, error=T}
c(T,T,T) & c(T,F,F)
c(T,T,T) && c(T,F,F)
IDontExist
T | IDontExist
T || IDontExist
```

#### Vectors

```{r}
# a simple numeric vector
myvector <- c(1,4,6)
myvector
# a vector of type character
myfamily <- c("Paula", "Ali", "Emma")
myfamily
# get the first element of a vector
myfamily[1]
# apply function to all items:
myvector + 1
paste(myfamily, "Meier")
# concatenate vectors:
longervector <- c(myvector, 5:7)
longervector
# create a sequence
odd <- seq(from = 1, to = 10, by = 2)
odd
# create a boring sequence
boring <- rep(1, 10)
boring
```

#### Factors

```{r}
fac <- factor(c("good", "better", "best"))
levels(fac)
nlevels(fac)
```

#### List of lists

You can create a list of lists (a list of vectors):

```{r}
myList <- list(smallLetters=letters[1:10], 
               capitalLetters=LETTERS[1:10], 
               numbers=1:5)
myList
```

If you want to choose lists, you can do it with a single bracket.

```{r}
# Accessing multiple elements
myList[1:2]
```

If you want to choose single elements, you need double brackets:

```{r}
# Accessing single elements
myList[2][2]
myList[[2]][2]
myList[[1:2]]
```

#### Matrices

```{r}
m <- matrix(data=1:12, nrow = 3, ncol = 4)
m
```

Element wise operations:

```{r}
m
# Element-wise operations
m * 0.5
```

```{r}
m
# Element-wise operations
m * c(1,2,3)
```

matrix/ vector multiplication

```{r}
m
# Matrix multiplication
m %*% c(1,2,3,4)
```

Good explanation of Matrix multiplication: [Eli Bendersky's website](https://eli.thegreenplace.net/2015/visualizing-matrix-multiplication-as-a-linear-combination/)

#### Data frames

```{r}
# Creating a data frame
family.frame <- data.frame(index = 1:3, firstname = myfamily, surname = rep("Meier", 3))
```

```{r}
library(knitr)
kable(family.frame)
```

### Python

A comprehensive list of data types is given in the [Python documentation](https://docs.python.org/3/library/datatypes.html).

#### Character aka [String](https://www.geeksforgeeks.org/python/python-string/)

```{python}
firstname = 'Pipi'
surname = 'Langstrumpf'

name = firstname+surname
print(name)

name = firstname+' '+surname
print(name)
```

#### [Numeric](https://www.geeksforgeeks.org/python/python-data-types/)

```{python}
import numpy as np

a = 1
b = 2
c = a + b
print(c)

d = b*c/a
print(d)

e = d ** 2
print(e)

f = int(3.14)
print(f)

g = float(3.14)
print(g)

h = np.nan
float(h)
```

#### [Logical](https://www.geeksforgeeks.org/python/python-logical-operators/)

```{python}
a = True
b = False

# or
a or b

# and
a and b

# not
not a

4 == 5

4 < 5
4 >= 4

```

#### [Vectors](https://www.digitalocean.com/community/tutorials/vectors-in-python) aka list

```{python}
# a simple numeric vector is similar to a list in python
myvector = [1,4,6]
print(myvector)

# a vector of type character
myfamily = ["Paula", "Ali", "Emma"]
print(myfamily)

# get the first element of a vector
myfamily[0]

# append another item:
myfamily.append("Meier")
print(myfamily)

# create a sequence
odd = list(range(1, 10, 2)) # start, stop, step
print(odd)

# create a boring sequence
boring = list(range(10))
print(boring)

# concatenate vectors:
longervector = myvector + odd
print(longervector)
```

#### Matrices aka [Array](https://www.geeksforgeeks.org/python/python-arrays/)

```{python}
import numpy as np
m = np.arange(1, 13).reshape(3, 4)  
print(m)
```

Element wise operations:

```{python}
# Element-wise operations
result = m * 0.5
print(result)
```

```{python}
m = np.arange(1, 13).reshape(3, 4)
n = np.array([1, 2, 3, 4])

# Element-wise operations
result = m * n
print(result)
```

matrix/ vector multiplication

```{python}
m = np.arange(1, 13).reshape(3, 4)
v = np.array([1, 2, 3, 4])

# Matrix multiplication
result = np.dot(m, v)
print(result)

# or:
result = np.matmul(m, v)
print(result)
```

Good explanation of Matrix multiplication: [Eli Bendersky's website](https://eli.thegreenplace.net/2015/visualizing-matrix-multiplication-as-a-linear-combination/)

#### Dataframes

Dataframes in Python are defined in the package [Pandas](https://pandas.pydata.org/docs/user_guide/10min.html).

```{python}
import pandas as pd
# Creating a data frame from a list

myfamily = ['Paula', 'Ali', 'Emma']
lastname = ['Meier']*3
family_frame = pd.DataFrame(list(zip(myfamily,lastname)),columns=['firstname','surname'])
family_frame
```
:::

# PANGAEA - Introduction

The slides of the PANGAEA theory part are stored in [github](https://github.com/TheDiren/RAndPythonCourse/blob/main/presentations/PANGAEA_slides.pdf).

# Basics R and Python

## Preparing your data for analysis

::: panel-tabset
### R

#### Reading the data

Usually, you would use the "csv" format to read data into R. Sometimes you have other formats, e.g. "txt". Optimally, you have exactly one line for the header. Make sure to choose the correct separator. You also have to tell R whether your file has a header or not.

```{r error=T}
df <- read.table("beedata.csv")
```

That did not work. Oh, yes, the separator!

```{r}
df <- read.table("beedata.csv", sep = ",")
```

```{r echo=F}
library(knitr)
kable(head(df, n = 5))
```

Looks ok, but we forgot the heading:

```{r}
df <- read.table("beedata.csv", sep = ",", header = T)
```

```{r  echo=F}
library(knitr)
kable(head(df, n = 5))
```

That looks good!

Alternatively, we can use "read.csv". In this case, the default parameters work for us.

```{r}
df <- read.csv("beedata.csv")
```

Take care, sometimes you don't get an error, but your data is screwed up anyway: ![sample Data](images/sampleData.png)

```{r}
df <- read.csv("sampleData.csv", sep = " ")
```

```{r  echo=F}
library(knitr)
kable(head(df, n = 5))
```

Use the head function to inspect your data.

#### Transforming entire columns

The columns/ variables of a dataframe basically behave like entries in a named list. Each element of this list is a vector of a specific type. You can inspect the structure of a dataframe using the function "str".

```{r}
df <- read.csv("beedata.csv")
str(df)
```

E.g. converting kg to g:

```{r}
df$weight_g <- df$weight_kg*1000
```

Marking high temperature values:

```{r}
df$highTemp <- df$t_i_1>25
```

```{r  echo=F}
library(knitr)
kable(head(df[,-(5:9)], n = 5))
```

Dealing with the timestamp (nanoseconds to seconds)

```{r}
df$time <- as.POSIXct(df$time/1000000000, origin="1970-01-01")
```

```{r  echo=F}
library(knitr)
kable(head(df, n = 5))
```

### Python

#### Reading data

One easy way to read ascii data in Python is via [Pandas](https://pandas.pydata.org/docs/user_guide/10min.html). Many different formats can be read, e.g. "csv", "txt" or "xlsx". Ideally, you have exactly one line for the header. Data formats can be very divers. However, there are as many [options](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to set before reading the data. Make sure to choose the correct separator.

```{python}
# import package
import pandas as pd

# open the data as dataframe 
df = pd.read_csv('beedata.csv')

# use head function to see the first 5 rows of the dataframe
df.head()

# use describe function to get an overview of the values of the dataframe
df.describe()
```

#### Transforming entire columns

The columns/ variables of a dataframe are called dataseries. Each item of each dataseries is of a specific type. You can inspect the structure of a dataframe using the function "info".

```{python}
# open the data as dataframe 
df = pd.read_csv('beedata.csv')

df.info()

# you can call each dataseries via it's header, e.g. 
df['weight_kg']
```

E.g. converting kg to g:

```{python}
df['weight_g'] = df['weight_kg']*1000.

df.head()
```

Marking high temperature values:

```{python}
df['highTemp'] = df['t_i_1']>25
```

Data can have various [date and time](https://docs.python.org/3/library/datetime.html#datetime-objects) formats. Here, we have timesteps of nanoseconds since 1970-01-01. Thus, dealing with the timestamp (nanoseconds to seconds)

```{python}
df['time'] = pd.to_datetime(df['time'], unit='ns', origin=pd.Timestamp('1970-01-01'))

df.info()
```

```{python}
df.head()
```

Take care, sometimes you don't get an error, but your data is screwed up anyway: ![sample Data](images/sampleData.png)

```{python}

df.head()
```

Use the head function to inspect your data.
:::

## Subsetting data

::: panel-tabset
### R

You can use squared brackets and boolean expressions to choose lines and columns: df\[\<expression to choose lines\>,\<expression to choose columns\>\]

Select and plot data from hive 4:

```{r}
df.4 <- df[df$hive==4,]
plot(df.4$time, df.4$t_o, ylim=c(0,40))
```

Select only the first 1000 lines:

```{r}
df.4.sub <- df.4[1:1000,]
plot(df.4.sub$time, df.4.sub$t_o, ylim=c(0,40))
```

Delete columns: / Choose only some columns

```{r}
names(df)
df.some <- df[, c(1,2,10)]
```

```{r  echo=F}
library(knitr)
kable(head(df.some, n = 5))
```

You can also use:

```{r}
df.same <- df[, c("time", "hive", "weight_kg")]
```

```{r  echo=F}
library(knitr)
kable(head(df.same, n = 5))
```

or

```{r}
df.or <- df[, -c(3:9,11)]
```

```{r  echo=F}
library(knitr)
kable(head(df.or, n = 5))
```

#### Useful functions

-   summary
-   head
-   tail
-   sum
-   mean

### Python

You can use squared brackets and boolean expressions to choose lines and columns.

Select and plot data from hive 4:

```{python}
df = pd.read_csv('beedata.csv')
df_4 = df[df['hive']==4]

import matplotlib.pyplot as plt

# quick plot with default arguments
plt.plot(df_4['time'],df_4['t_o'])
```

For more plotting options see <https://matplotlib.org/stable/gallery/index.html>

```{python}
fig, ax = plt.subplots()

ax.plot(df_4['time'],df_4['t_o'],'x')

ax.set(ylim=(0, 40))
plt.show()
```

Select only the first 1000 lines:

```{python}
df_4_sub = df_4[1:1000]

# combine head and atil and show the first and last 2 rows
pd.concat([df_4_sub.head(2),df_4_sub.tail(2)])
```

Delete columns: / Choose only some columns

```{python}
df.columns
df_some = df[["time", "hive", "weight_kg"]] 
pd.concat([df_some.head(2),df_some.tail(2)])
```

#### Useful functions

-   info\
-   head\
-   tail\
-   describe\
-   columns
:::

## Exercises - Data

::: panel-tabset
### R

```{r eval=F}
## Exercises about data types

# 1. Create following sequences: 
# 4, 8, 12, 16, 20, 24, 28
# 10, 8, 6, 4, 2, 0
# repeat "chocolate" 10 times in a vector


# 2. Starting with the following code, divide a by b and save it as variable c:

a <- "5555555"
b <- 3


# 3. Starting with following code, create the string/ character vector "group3trial1.csv"

group <- 3
trial <- 1


## Exercises about data frames

# 1. Read the data "allForarexData.csv"

# 2. Convert Exp0_OxygenTemp and Exp1_OxygenTemp. Devide by 1000. Save the result in the same column.

# 3. What are the means of Exp0_OxygenTemp and Exp1_OxygenTemp?


# 4. Save the timestamp in the correct format in UTC. The time was measured in seconds. (origin="1970-01-01")


# 5. When was the first measurement? When was the last measurement?

# 6. Create a subset containing only data measured after 2019-03-09 09:25:52.

# 7. Difficult: Exclude columns, where all measurements are the same. 
# hint at the bottom of the file


## Exercises about both data frames and data types

# Use beedata.csv

# 1. Select the lines of the bee data set where the hive number is 13 or 14.

# 2. What are the classes of the beedata's columns hive and t_i_1?

# 3. Difficult: How can you print the classes of all columns?







# Hint
# hint "Data types", 7: one option is to check if the min value of a column equals the max value. You can use a loop or following function: sapply(flight, function(x){min(x)!=max(x)})

```

### R - Solutions

```{r eval=F}
## Exercises about data types

# 1. Create following sequences: 
# 4, 8, 12, 16, 20, 24, 28
# 10, 8, 6, 4, 2, 0
# repeat "chocolate" 10 times in a vector

seq(4,28,4)
seq(10,0,-2)
rep("chocolate", 10)


# 2. Starting with the following code...:

a <- "5555555"
b <- 3


c <- as.numeric(a) / b


# 3. Starting with following code, create the filename "group3trial1.csv"

group <- 3
trial <- 1

paste("group", group, "trial", trial, ".csv", sep="")


## Exercises about data frames

# 1. Read the data "allForarexData.csv"
flight <- read.table("allForarexData.csv", header = T, sep = ",")

# 2. Convert Exp0_OxygenTemp and Exp1_OxygenTemp. Devide by 1000. Save the result in the same column.
flight$Exp0_OxygenTemp <- flight$Exp0_OxygenTemp/1000
flight$Exp1_OxygenTemp <- flight$Exp1_OxygenTemp/1000

# 3. What are the means of Exp0_OxygenTemp and Exp1_OxygenTemp?
mean(flight$Exp0_OxygenTemp)
mean(flight$Exp1_OxygenTemp)

# 4. Save the timestamp in the correct format in UTC. The time was measured in seconds.
flight$timeStamp <- as.POSIXct(flight$timeStamp, origin="1970-01-01", tz = "UTC")

# 5. When was the first measurement? When was the last measurement?
min(flight$timeStamp)
max(flight$timeStamp)

# 6. Create a subset containing only data measured after 2019-03-09 09:25:52.

flight.subtime <- flight[flight$timeStamp>"2019-03-09 09:25:52",]

# 7. Difficult: Exclude columns, where all measurements are the same. 

# hint: one option is using: sapply(flight, function(x){min(x)!=max(x)})

ncol(flight)
flight.sub <- flight[, sapply(flight, function(x){min(x)!=max(x)})]
ncol(flight.sub)

## Exercises about both data frames and data types

# Use beedata.csv

# 1. Select the lines of the bee data set where the hive number is 13 or 14.

df.13or14 <- df[df$hive==13|df$hive==14,]


# 2. What are the classes of the beedata's columns hive and t_i_1?

class(df$hive)
class(df$t_i_1)

# 3. Difficult: How can you print the classes of all columns?

lapply(df, class)

```

### Python

```{python}
## Exercises about data types

# 1. Create following sequences: 
# 4, 8, 12, 16, 20, 24, 28
# 10, 8, 6, 4, 2, 0
# repeat "chocolate" 10 times in a vector


# 2. Starting with the following code, divide a by b and save it as variable c:

a = "5555555"
b = 3


# 3. Starting with following code, create the string/ character vector "group3trial1.csv"

group = 3
trial = 1


## Exercises about data frames

# 1. Read the data "allForarexData.csv"

# 2. Convert Exp0_OxygenTemp and Exp1_OxygenTemp. Devide by 1000. Save the result in the same column.

# 3. What are the means of Exp0_OxygenTemp and Exp1_OxygenTemp?

# 4. Save the timestamp in the correct format. The time was measured in seconds. (origin="1970-01-01")

# 5. When was the first measurement? When was the last measurement?

# if you are unsure whether the data are chronologically sorted

# 6. Create a subset containing only data measured after 2019-03-09 09:25:52.

# 7. Difficult: Exclude columns, where all measurements are the same. 
```

Hint: there is a function called [nunique](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html)

```{python}
## Exercises about both data frames and data types

# Use beedata.csv

# 1. Select the lines of the bee data set where the hive number is 13 or 14.

# 2. What are the classes of the beedata's columns hive and t_i_1?

# 3. Difficult: How can you print the classes of all columns?


```

### Python - Solutions

```{python eval=F}
## Exercises about data types

# 1. Create following sequences: 
# 4, 8, 12, 16, 20, 24, 28
# 10, 8, 6, 4, 2, 0
# repeat "chocolate" 10 times in a vector

sequence = list(range(4, 29, 4))
print(sequence)

sequence = list(range(10, -1, -2))
print(sequence)

words = ["chocolate"] * 10
print(words)


# 2. Starting with the following code...:

a = "5555555"
b = 3

c = int(a) / b
print(c)


# 3. Starting with following code, create the filename "group3trial1.csv"

group = 3
trial = 1

filename = "group" + str(group) + "trial" + str(trial) + ".csv"
print(filename)


## Exercises about data frames

# 1. Read the data "allForarexData.csv"

# import package
import pandas as pd

# open the data as dataframe 
df = pd.read_csv('/isibhv/projects/p_pangaea_proces/kriemann/python/2025_informatica/allForarexData.csv')

# use head function to see the first 5 rows of the dataframe
df.head()

# 2. Convert Exp0_OxygenTemp and Exp1_OxygenTemp. Devide by 1000. Save the result in the same column.
df['Exp0_OxygenTemp'] = df['Exp0_OxygenTemp']/1000.
df['Exp1_OxygenTemp'] = df['Exp1_OxygenTemp']/1000.

# 3. What are the means of Exp0_OxygenTemp and Exp1_OxygenTemp?
print(df['Exp0_OxygenTemp'].mean())
print(df['Exp1_OxygenTemp'].mean())

# 4. Save the timestamp in the correct format. The time was measured in seconds. (origin="1970-01-01")
df['timeStamp'] = pd.to_datetime(df['timeStamp'], unit='s', origin=pd.Timestamp('1970-01-01'))
df.head()

# 5. When was the first measurement? When was the last measurement?

# if you are unsure whether the data are chronologically sorted
df = df.sort_values(by=['timeStamp'], ascending=True)

df.head(1)
df.tail(1)

# 6. Create a subset containing only data measured after 2019-03-09 09:25:52.

df_subtime = df[df['timeStamp']>'2019-03-09 09:25:52']
df_subtime.head()

# 7. Difficult: Exclude columns, where all measurements are the same. 
```

hint: there is a function called [nunique](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nunique.html)

```{python}
constant_columns = [col for col in df.columns if df[col].nunique() == 1]

print("Constant columns:", constant_columns)

df_sub = df.drop(constant_columns, axis=1)

## Exercises about both data frames and data types

# Use beedata.csv

# 1. Select the lines of the bee data set where the hive number is 13 or 14.
filtered_df = df[(df['hive'] == 13) | (df['hive'] == 14)]
filtered_df.head()

# 2. What are the classes of the beedata's columns hive and t_i_1?

# 3. Difficult: How can you print the classes of all columns?

# This is not at all difficult in python:
df.info()

```
:::

## Conditions - If and Else

::: panel-tabset
### R

#### If

![](images/if.png){width="75%"}

Simple if:

```{r}
a <- 19
if(a >= 18){
  print("Yes, you are allowed to see this content.")
}
```

if and else:

![](images/ifelse.png){width="75%"}

```{r}
goodWeather <- TRUE
if (goodWeather){
  print("Let's go to the beach!")
} else{
  print("Let's eat pizza.")
}

```

Else-if:

![](images/elseif.png){width="75%"}

```{r}

do.you.want.this <- "chocolate"
#do.you.want.this <- "cookies"
#do.you.want.this <- "carrots"
if (do.you.want.this == "chocolate"){
  print("Yes, I love chocolate!")
} else if (do.you.want.this == "cookies"){
  print("Yes, if they are with chocolate.")
} else {
  print("Hm, not sure. Do you have chocolate?")
}
```

```{r include=F}
library(lubridate)
```

```{r}
library(lubridate)
birthday <- as.POSIXct("2019-08-06 10:50:18")
what.do.you.want.to.know <- "year"
#what.do.you.want.to.know <- "month"
#what.do.you.want.to.know <- "chocolate"
if (what.do.you.want.to.know == "year"){
  print(year(birthday))
} else if (what.do.you.want.to.know == "month"){
  print(month(birthday))
} else {
  print("Sorry, what do you want to know?")
}
```

### Python

#### If

![](images/if.png){width="75%"}

**Note:** *if*, *else*, etc. do not use (),{} or \[\] to mark its beginning and endings. Python uses indentations.

Simple if:

```{python}
a = 19
if a >= 18:
    print("Yes, you are allowed to see this content.")
```

if and else:

![](images/ifelse.png){width="75%"}

```{python}
goodWeather = True
if goodWeather:
    print("Let's go to the beach!")
else:
    print("Let's eat pizza.")

```

elif (short for else if):

![](images/elseif.png){width="75%"}

```{python}

do_you_want_this = "chocolate"
#do_you_want_this = "cookies"
#do_you_want_this = "carrots"
if do_you_want_this == "chocolate":
    print("Yes, I love chocolate!")
elif do_you_want_this == "cookies":
    print("Yes, if they are with chocolate.")
else:
    print("Hm, not sure. Do you have chocolate?")

```

```{python}
from datetime import datetime
birthday = datetime.fromisoformat('2019-08-06 10:50:18')

what_do_you_want_to_know = "year"
#what_do_you_want_to_know = "month"
#what_do_you_want_to_know = "chocolate"
if what_do_you_want_to_know == "year":
    print(birthday.year)
elif what_do_you_want_to_know == "month":
    print(birthday.month)
else:
    print("Sorry, what do you want to know?")

```
:::

## For and While

::: panel-tabset
### R

#### For

```{r}
ages <- c(31, 29, 5)
total.age <- 0
for(i in ages){
  total.age <- total.age + i
}
total.age
```

```{r}
myfamily <- list(Paula=31, Ali=29, Emma=5)
age <- 0
for (i in 1:length(myfamily)){
  age <- age + myfamily[[i]]
}
age
```

apply it to columns:

```{r}
for (i in 1:ncol(df)){
  name <- names(df)[i]
  colclass <- class(df[,i])
  print(paste(name, ":", colclass))
}
```

transform long code ...

```{r eval=F}
df <- read.csv("beedata.csv")
print("mean of h:")
mean(df$h)
print("mean of t_i_1:")
mean(df$t_i_1)
print("mean of weight_kg:")
mean(df$weight_kg)
print("missing h values:")
sum(is.na(df$h))
print("missing t_i_1 values:")
sum(is.na(df$h))
print("missing weight_kg values:")
sum(is.na(df$h))
```

... into shorter code

```{r eval=F}
to.analyse <- c("h", "t_i_1", "weight_kg")
for(i in 1:length(to.analyse)){
  print(paste("mean of", to.analyse[i], ":"))
  print(mean(to.analyse[i]))
  print(paste("missing", to.analyse[i], "values:"))
  print(sum(is.na(df[,to.analyse[i]])))
}
```

![](images/for.png){width="75%"}

#### While

```{r}
a <- 2
while (a<1000){
  a <- a^2
  print(a)
}
```

![](images/while.png){width="75%"}

#### Do-while

```{r}
a <- 10
repeat{
  a <- a - sqrt(a)
  print(a)
  if(sqrt(a) > a){
    break
  }
}
```

bad example for Do-while:

```{r}
a <- 10
repeat{
  a <- a - sqrt(a)
  print(a)
  if(a < 0){
    break
  }
}
```

because it breaks for edge cases:

```{r error=TRUE}
a <- -10
repeat{
  a <- a - sqrt(a)
  print(a)
  if(a < 0){
    break
  }
}
```

![](images/do-while.png){width="75%"}

#### For vs. While

-   if you do not know the number of iterations needed, use while
-   else, always use for!
-   it is easier to create a while-loop that never stops, than creating a for-loop that never stops.

### Python

#### For

**Note:** *for*, *while*, etc. do not use (),{} or \[\] to mark its beginning and endings. Python uses indentations.

```{python}
ages = [31, 29, 5]
total_age = 0

for i in ages:
    total_age = total_age + i
print(total_age)
```

same as:

```{python}
ages = [31, 29, 5]
total_age = 0

for age in ages:
    total_age = total_age + age
print(total_age)
```

The next example uses a [dictionary](https://docs.python.org/3/tutorial/datastructures.html#dictionaries) with {key:value} structure.

```{python}
myfamily = {'Paula':31, 'Ali':29, 'Emma':5}
age = 0
for key, value in myfamily.items():
    age = age + value
print(age)
```

apply it to dataframes:

```{python}
import pandas as pd

df = pd.read_csv('beedata.csv')

for ind,value in df['t_i_1'].items():
    if ind > 6 and ind <= 10:
        print('ind = ',ind)
        print('value = ',value)
        
```

transform long code ...

```{python}
import pandas as pd

df = pd.read_csv('beedata.csv')

print("mean of h:")
df['h'].mean()
print("mean of t_i_1:")
df['t_i_1'].mean()
print("mean of weight_kg:")
df['weight_kg'].mean()
print("missing h values:")
df['h'].isna().sum()
print("missing t_i_1 values:")
df['t_i_1'].isna().sum()
print("missing weight_kg values:")
df['weight_kg'].isna().sum()
```

... into shorter code

```{python}
to_analyse = ["h", "t_i_1", "weight_kg"]
for i in to_analyse:
    print("mean of", i, df[i].mean())
    print("sum of missing values of", i, df[i].isna().sum())

```

![](images/for.png){width="75%"}

#### While

```{python}
a = 2
while (a<1000):
    a = a**2
    print(a)

```

![](images/while.png){width="75%"}

#### Do-while

```{python}
import math

a = 10
while True:
    a = a - math.sqrt(a)
    print(a)
    if math.sqrt(a) > a:
        break

```

bad example for Do-while:

```{python}
import math

a = 10
while True:
    a = a - math.sqrt(a)
    print(a)
    if a < 0:
        break
```

because it breaks for edge cases:

```{python}
import math

a = -10
while True:
    try:
        a = a - math.sqrt(a)
    except ValueError:
        print("math domain error: sqrt(a) with negative a is not defined")
        break
    print(a)
    if a < 0:
        break

```

![](images/do-while.png){width="75%"}

#### For vs. While

-   if you do not know the number of iterations needed, use while
-   else, always use for!
-   it is easier to create a while-loop that never stops, than creating a for-loop that never stops.
:::

## Exercises - Conditions, For and While

::: panel-tabset
### R

```{r eval=F}
  
# 1. Imagine somebody tells you the age of two of her friends,
# Ali and Bea. If Ali is older than Bea print 
# "Ali is older than Bea.". If Bea is older than Ali,
# print "Bea is older than Ali.".

Ali <- 5555/111
Bea <- 10*5




## For and While

#  1. Loop from 1 to 15 and print the square-root of 
# each number

# 2. The function "rbinom(1,1,0.9)" models a very unfair
# coin, which shows the head (1) with a probability 
# of 90 %. Flip this coin until you get tail (0). 
# Count how many times you flipped the coin.

# 3. Repeat each character of the string "Summer" 3 times.
# Combine all characters to a new string. 

# hint at the bottom of this file



# 4. Difficult: Read in all files in the directory 
# "forarexData" and combine them to a single data frame.

# hint at the bottom of this file






# Hints


# Watch out, spoiler alert!

# hint "For and While", 3:  Check out the functions "substr" and "nchar".





# hint "For and While", 4:  Useful functions: list.files, try or try-catch, rbind



# hint "Functions" 1: in case you did not find the solution. This is the solution:

# Watch out this is a solution for another task!


s <- "summer"
s1 <- ""
for(i in 1:nchar(s)){
  for(j in 1:3){
    s1 <- paste(s1, substr(s, i, i), sep = "")
  }
}
s1


```

### R - Solutions

```{r eval=F}
## Exercises - Conditions

# 1. Imagine somebody tells you the age of two of her friends,
# Ali and Bea. If Ali is older than Bea print 
# "Ali is older than Bea.". If Bea is older than Ali,
# print "Bea is older than Ali.".

Ali <- 5555/111
Bea <- 10*5

if (Ali>Bea){
  print("Ali is older than Bea.")
} else{
  print("Bea is older than Ali.")
}

# 2. The price of a small bar of chocolate is 1 Euro. 
# For a medium bar of chocolate you have to pay 3 Euros 
# and for a large bar you have to pay 5 Euros.
# Somebody tells you how much money she has. 
# Tell her, how much chocolate she can buy 
# (Eg. print "You can buy a small bar of chocolate.")
# She does not want to buy more than one bar of chocolate, 
# but the largest possible.

money <- 14/3

if (money >= 5){
  print("You can buy a large bar of chocolate.")
} else if (money >= 3){
  print("You can buy a medium bar of chocolate.")
} else if (money >= 1){
  print("You can buy a small bar of chocolate.")
} else{
  print("Sorry, you can't buy any chocolate.")
}

## For and While

#  1. Loop from 1 to 15 and print the square-root of 
# each number

for (i in 1:15){
  print(sqrt(i))
}

# 2. The function "rbinom(1,1,0.9)" models a very unfair
# coin, which shows the head (1) with a probability 
# of 90 %. Flip this coin until you get tail (0). 
# Count how many times you flipped the coin.

coin <- 1
index <- 0
while (coin!=0){
  coin <- rbinom(1,1,0.9)
  index <- index +1
}
index

# or

index <- 0
repeat{
  coin <- rbinom(1,1,0.9)
  index <- index +1
  if(coin==0){
    break
  }
}
index

# 3. Repeat each character of the string "Summer" 3 times.
# Combine all characters to a new string. 

# hint:  Check out the functions "substr" and "nchar".

s <- "summer"
s1 <- ""
for(i in 1:nchar(s)){
  for(j in 1:3){
    s1 <- paste(s1, substr(s, i, i), sep = "")
  }
}
s1


# 4. Difficult: Read in all files in the directory 
# "forarexData" and combine them to a single data frame.

# hint:  Useful functions: list.files, try or try-catch, rbind

dir <- "forarexData/"
files <- list.files(dir)
files <- paste(dir, files, sep="")

df<-data.frame()

for (i in 1:length(files)) {
  tmp <- read.csv(file = files[i])
  df <- rbind(df,tmp)
}


```

### Python

```{python eval=F}
  
# 1. Imagine somebody tells you the age of two of her friends,
# Ali and Bea. If Ali is older than Bea, print 
# "Ali is older than Bea.". If Bea is older than Ali,
# print "Bea is older than Ali.".

Ali = 5555/111
Bea = 10*5


# 2. The price of a small bar of chocolate is 1 Euro. 
# For a medium bar of chocolate you have to pay 3 Euros 
# and for a large bar you have to pay 5 Euros.
# Somebody tells you how much money she has. 
# Tell her, how much chocolate she can buy 
# (Eg. print "You can buy a small bar of chocolate.")
# She does not want to buy more than one bar of chocolate, 
# but the largest possible.

money = 14/3


## For and While

# 1. Loop from 1 to 15 and print the square-root of 
# each number

# hint: you need the package numpy for square-roots
import numpy as np

# 2. The function "np.random.binomial(n=1, p=0.9, size=1)" models a very unfair
# coin, which shows the head (1) with a probability 
# of 90 %. Flip this coin until you get tail (0). 
# Count how many times you flipped the coin.

# 3. Repeat each character of the string "Summer" 3 times.
# Combine all characters to a new string. 

# hint at the bottom of this file



# 4. Difficult: Read in all files in the directory 
# "forarexData" and combine them to a single data frame.

# hint at the bottom of this file













# Hints


# Watch out, spoiler alert!

# hint "For and While", 3:  The function "len" works also for strings.





# hint "For and While", 4:  useful functions: os.listdir, os.path.join(), pd.concat

import os
import pandas as pd


```

### Python - Solutions

```{python eval=F}
## Exercises - Conditions

# 1. Imagine somebody tells you the age of two of her friends,
# Ali and Bea. If Ali is older than Bea, print 
# "Ali is older than Bea.". If Bea is older than Ali,
# print "Bea is older than Ali.".

Ali = 5555/111
Bea = 10*5

if Ali > Bea:
    print("Ali is older than Bea.")
else:
    print("Bea is older than Ali.")


# 2. The price of a small bar of chocolate is 1 Euro. 
# For a medium bar of chocolate you have to pay 3 Euros 
# and for a large bar you have to pay 5 Euros.
# Somebody tells you how much money she has. 
# Tell her, how much chocolate she can buy 
# (Eg. print "You can buy a small bar of chocolate.")
# She does not want to buy more than one bar of chocolate, 
# but the largest possible.

money = 14/3

if money >= 5:
    print("You can buy a large bar of chocolate.")
elif money >= 3:
    print("You can buy a medium bar of chocolate.")
elif money >= 1:
    print("You can buy a small bar of chocolate.")
else:
    print("Sorry, you can't buy any chocolate.")


## For and While

# 1. Loop from 1 to 15 and print the square-root of 
# each number

# you need the package numpy to compute square-roots
import numpy as np

for i in range(1,16):
    print(np.sqrt(i))

    
# 2. The function "np.random.binomial(n=1, p=0.9, size=1)" models a very unfair
# coin, which shows the head (1) with a probability 
# of 90 %. Flip this coin until you get tail (0). 
# Count how many times you flipped the coin.

coin = 1
index = 0

while coin!=0:
    coin = np.random.binomial(n=1, p=0.9, size=1)
    index = index +1

print(index)



# 3. Repeat each character of the string "Summer" 3 times.
# Combine all characters to a new string. 

s = "summer"
s1 = ""

for i in range(len(s)):
    for j in range(3):
        s1 += s[i]

print(s1)


# 4. Difficult: Read in all files in the directory 
# "forarexData" and combine them to a single data frame.

# hint:  Useful functions: os.listdir, os.path.join(), pd.concat

import os
import pandas as pd

dir = "forarexData/"
files = os.listdir(dir)
files = [os.path.join(dir, f) for f in files]

df = pd.DataFrame()
for file in files:
    tmp = pd.read_csv(file)
    df = pd.concat([df, tmp], ignore_index=True)

print(df)

```
:::

## Writing own functions

::: panel-tabset
### R

The basic syntax to write functions looks like this:

```{r}
myPlus <- function(a, b){
  return(a + b)
}
myPlus(1,2)
```

You can use default parameters:

```{r}
myPlus <- function(a=1, b=1){
  return(a + b)
}
myPlus(1,2)
myPlus()
```

If you want to return multiple values, you can use a named list:

```{r}
dataframe.info <- function(df){
  cells.count <- ncol(df)*nrow(df)
  return(list(columns=ncol(df), rows=nrow(df), cells= cells.count))
}
dataframe.info(df)
```

### Python

The basic syntax to write functions looks like this:

```{python}
def myPlus(a, b):
    c = a+b
    return c
    
myPlus(1,2)
```

You can use default parameters:

```{python}
def myPlus(a=1, b=1):
    c = a+b
    return c
    
myPlus(1,2)
myPlus()
```

Example to return multiple values:

```{python}
def dataframe_info(df):

    rows_count = df.shape[0]
    columns_count = df.shape[1]
    values_count = df.shape[0]*df.shape[1]

    return columns_count, rows_count, values_count

import pandas as pd
df = pd.read_csv('beedata.csv')

dataframe_info(df)
```
:::

## Exercises: Functions

::: panel-tabset
### R

```{r eval=F}

# 1. In one of the previous tasks you wrote some code to
# Repeat each character of the string "Summer" 3 times.
# Convert it into a function. It should take two parameters:
# - a string, e.g. “summer”.
# - A number, e.g. 3 to specify how often each letter 
#   should be repeated.
# Use “summer” and 3 as default values.

# hint at the bottom of this file


# 2. We look at the data from the beehives again. 
# Given a beehive, how many observations do we have
# for that beehive? How many observations are missing
# in the column “weight_kg”? Write a function for this
# problem. Return both values in a named list.
# Use the dataframe and the hive number as input parameters.

# 3. Difficult-follow-up: In a previous exercise, you wrote some code to read
# in all files within a directory. 
# Convert the code to a function.








# Hints
# hint "Functions" 1: in case you did not find the solution. This is the solution:

# Watch out this is a solution for another task!


s <- "summer"
s1 <- ""
for(i in 1:nchar(s)){
  for(j in 1:3){
    s1 <- paste(s1, substr(s, i, i), sep = "")
  }
}
s1


```

### R - Solutions

```{r eval=F}
# 1. In one of the previous tasks you wrote some code to
# Repeat each character of the string "Summer" 3 times.
# Convert it into a function. It should take two parameters:
# - a string, e.g. “summer”.
# - A number, e.g. 3 to specify how often each letter 
#   should be repeated.
# Use “summer” and 3 as default values.
# hint: in case you did not find the solution. This is the solution:

# Watch out this is a solution for another task!


s <- "summer"
s1 <- ""
for(i in 1:nchar(s)){
  for(j in 1:3){
    s1 <- paste(s1, substr(s, i, i), sep = "")
  }
}
s1

funny.words <- function(word=summer, repeat.times=3) {
  s1 <- ""
  for(i in 1:nchar(word)){
    for(j in 1:repeat.times){
      s1 <- paste(s1, substr(word, i, i), sep = "")
    }
  }
  return(s1)
}

# 2. We look at the data from the beehives again. 
# Given a beehive, how many observations do we have
# for that beehive? How many observations are missing
# in the column “weight_kg”? Write a function for this
# problem. Return both values in a named list.
# Use the dataframe and the hive number as input parameters.

df <- read.csv("beedata.csv")

beehive.info <- function(df, hive){
  sub <- df[df$hive==hive,]
  n <- nrow(sub)
  missing <- sum(is.na(sub$weight_kg))
  return(list(n=n, missing=missing))
}
beehive.info(df, 4)
beehive.info(df, 13)

# 3. In a previous exercise, you wrote some code to read
# in all files within a directory. 
# Convert the code to a function.


combine <- function(dir="forarexData/", finalName="forarexCombined.csv"){
  # Purpose: the function can combine the files and save to a new csv
  # Parameters:
  #  dir: the directory of the files to be combined
  #  finalName: the name of the file to be used to save the csv
  
  # list all files in directory
  files <- list.files(dir)
  files <- paste(dir, files, sep="")
  
  df<-data.frame()
  
  for (i in 1:length(files)) {
    tmp <- read.csv(file = files[i])
    df <- rbind(df,tmp)
  }
  write.csv(df, finalName)
}

combine()

### Other option with try

combine.try <- function(dir="forarexData/", finalName="forarexCombined.csv"){
  # Purpose: the function can combine the files and save to a new csv
  # Parameters:
  #  dir: the directory of the files to be combined
  #  finalName: the name of the file to be used to save the csv
  
  # list all files in directory
  files <- list.files(dir)
  files <- paste(dir, files, sep="")
  
  df<-data.frame()
  
  for (i in 1:length(files)) {
    try({
      tmp <- read.csv(file = files[i])
      df <- rbind(df,tmp)
    })
  }
  write.csv(df, finalName)
}
combine.try()

# option with trycatch, in case some files are completly screwed up

combine.trycatch <- function(dir="forarexData/", finalName="forarexCombined.csv"){
  # Purpose: the function can combine the files and save to a new csv
  # Parameters:
  #  dir: the directory of the files to be combined
  #  finalName: the name of the file to be used to save the csv
  
  # list all files in directory
  files <- list.files(dir)
  files <- paste(dir, files, sep="")
  
  df<-data.frame()
  
  for (i in 1:length(files)) {
    tryCatch({
      tmp <- read.csv(file = files[i])
      df <- rbind(df,tmp)
    },
    warning = function(warning_condition){
      print(paste("Some weird formatting in file", files[i]))
      print(warning_condition)
    },
    # handling of errors, if there was some wrong formating
    error = function(error_condition){
      print(paste("Skipping file", files[i]))
      print(error_condition)
    })
  }
  write.csv(df, finalName)
}
combine.trycatch()

```

### Python

```{python}
# 1. In one of the previous tasks you wrote some code to
# repeat each character of the string "Summer" 3 times.
# Convert it into a function. It should take two parameters:
# - a string, e.g. “summer”.
# - A number, e.g. 3 to specify how often each letter 
#   should be repeated.
# Use “summer” and 3 as default values.

# hint at the bottom of this file


# 2. We look at the data from the beehives again. 
# Given a beehive, how many observations do we have
# for that beehive? How many observations are missing
# in the column “weight_kg”? Write a function for this
# problem. Return both values in a named list.
# Use the dataframe and the hive number as input parameters.

# 3. Difficult-follow-up: In a previous exercise, you wrote some code to read
# in all files within a directory. 
# Convert the code to a function.








# Hints
# hint "Functions" 1: in case you did not find the solution. This is the solution:

# Watch out this is a solution for another task!


s = "summer"
s1 = ""

for i in range(len(s)):
    for j in range(3):
        s1 += s[i]

print(s1)


```

### Python - Solutions

```{python eval=F}

# 1. In one of the previous tasks you wrote some code to
# Repeat each character of the string "Summer" 3 times.
# Convert it into a function. It should take two parameters:
# - a string, e.g. “summer”.
# - A number, e.g. 3 to specify how often each letter 
#   should be repeated.
# Use “summer” and 3 as default values.
# hint: in case you did not find the solution. This is the solution:

# Watch out this is a solution for another task!

s = "summer"
s1 = ""

for i in range(len(s)):
    for j in range(3):
        s1 += s[i]

print(s1)


def funny_words(word="summer", repeat_times=3):
    s1 = ""
    for i in range(len(word)):
        for j in range(repeat_times):
            s1 += word[i]
    return s1



# 2. We look at the data from the beehives again. 
# Given a beehive, how many observations do we have
# for that beehive? How many observations are missing
# in the column “weight_kg”? Write a function for this
# problem. Return both values in a named list.
# Use the dataframe and the hive number as input parameters.

import pandas as pd

df = pd.read_csv("beedata.csv")

def beehive_info(df, hive):
    sub = df[df['hive'] == hive]
    n = len(sub)
    missing = sub['weight_kg'].isna().sum()
    return {'n': n, 'missing': missing}

# examples
result_4 = beehive_info(df, 4)
result_13 = beehive_info(df, 13)

print(result_4)
print(result_13)




# 3. In a previous exercise, you wrote some code to read
# in all files within a directory. 
# Convert the code to a function.


import os
import pandas as pd

def combine(dir="forarexData/", final_name="forarexCombined.csv"):
    # list all files in directory
    files = os.listdir(dir)
    files = [os.path.join(dir, f) for f in files]
    
    # crreate new and empty dataframe
    df = pd.DataFrame()
    for file in files:
        tmp = pd.read_csv(file)
        df = pd.concat([df, tmp], ignore_index=True)
    
    df.to_csv(final_name, index=False)

# call function
combine()



```
:::

## Debugging

::: panel-tabset
### R

Here is a buggy version of the function “funny.words.”

```{r}
funny.words <- function(s = "summer", count = 3){
  s = "summer"
  s1 <- ""
  for(i in 1:2){
    for(i in 1:count){
      print(substr(s, i, i))
      s1 <- paste(s1, substr(s, i, i), sep = "")
    }
  }
  return(s1)
}
funny.words()

funny.words("banana", 5)
```

Since this code consists of a function and a loop, we cannot run line by line to find the mistakes. However, we can create breakpoints by clicking next to the line numbering (left).

![](images/debugging.jpeg)

Then we can click on “source”" to execute all code until the first breakpoint.

![](images/source.jpeg)

In the console, there will be a new set of buttons:

![](images/buttons.jpeg)

-   If you click on Next, R will execute the next line. (e.g. line 6)
-   If you click on the second button, R will step in the current function call, so it will basically jump into an other function. (e.g. into the print function)
-   If you click on the third button, R will execute the rest of the current function or loop. (e.g. line 6 and 7)
-   If you click on “continue”“, R will run until we come across the next breakpoint. (e.g. in the next round of the loop or in line 10)
-   If you click on “Stop”, R will exit the debug mode.

### Python

Here is a buggy version of the function “funny_words.”. We are using the package *ipdb* for debugging.\
Implement `ipdb.set_trace()` into the function to set a [*Breakpoint*](https://www.geeksforgeeks.org/python/how-to-add-a-breakpoint-in-jupyter-notebook/) in the execution of the loop. You can step through the code and print out variables.

```{python}

# import ipdb

def funny_words(s = "summer", count = 3):
    s = "summer"
    s1 = ""
    
    for i in range(2):
        for i in range(count):
            # ipdb.set_trace()  # Pause the execution to inspect 's', 'i' and 'i'
            print(s, i, i)

    s1 =[s, i, i] 

    return s1

```

try out:

```{python}
funny_words()
```

and

```{python}
funny_words("banana", 5)
```

![](images/example_debugging_python.png)

You can use the following debugging commands to e.g. print variables or continue the loop until the next breakpoint:\
- p <variable_name>: print the value of a variable\
- c: continue to the next breakpoint\
- n: move to the next line of code\
- q: quit the debugging session

![](images/example_debugging_python2.png)
:::

## Piping

::: panel-tabset
### R

Some people complain about all the brackets in the R syntax. With using pipes you can get rid of them. Pipes might also reflect your workflow more naturally than the usual syntax.

You can find the standard pipe operator in multiple packages, but you will get more options when using the magrittr packages.

Here is a simple example

```{r}
library(magrittr)
x <- 9
# Calculate the square-root of x
sqrt(x)

# Calculate it using pipes
x %>% sqrt

```

In case you want to update x, you can use:

```{r}
x <- 9
# Calculate the square-root of x and update x
x <- sqrt(x)
x

# Calculate it using pipes
x <- 9
x %<>% sqrt
x
```

This is an example with two functions and additional arguments:

```{r}

nrow(subset(df, hive==4))

df %>% subset(hive==4) %>% nrow

```

### Python

There is no equivalent of piping in python.
:::

# PANGAEA - downloading data

::: panel-tabset
### R

An example script to download data from PANGAEA via the toolbox PANGAEAr is in [github](https://github.com/TheDiren/RAndPythonCourse/blob/main/code_R/R_downloading_manipulating.R).

### Python

An example script to download data from PANGAEA via the toolbox PANGAEApy is in [github](https://github.com/TheDiren/RAndPythonCourse/blob/main/code_python/Downloading_and_manipulating_PANGAEA_data.ipynb).
:::

# Data Cleaning

::: panel-tabset
### R

An example script to clean up data is in [github](https://github.com/TheDiren/RAndPythonCourse/blob/main/code_R/).

### Python

An example script to clean up data is in [github](https://github.com/TheDiren/RAndPythonCourse/blob/main/code_python/Cleaning_and_preprocessing_data.ipynb).
:::

# Statistics

## First Step: Look at your data (Descriptive Statistics)

-   What is your response variable?
-   Plot your data
    -   Plot raw data
    -   Frequency distribution -\> Are there any patterns?

## Definition - Simple Linear Regression

$$
\begin{equation}
y_i = \beta_0 + \beta_1x_i  + \epsilon_i, \qquad   i=1,...,n
\end{equation}
$$ where $y$ is the dependent variable, $x$ is the independent variable (also called explanatory variable), $\beta_0$ is the intercept parameter, $\beta_1$ is the slope parameter and $\epsilon\sim N(0,\sigma^2)$ is the error coefficient.

## Sample data

```{r}
set.seed(123)
x <- seq(0,5,0.1) 
y <- x + rnorm(length(x))
plot(x, y)
hist(y)

```

## Fitting a Linear Model

```{r}


mod <- lm(y~x)
summary(mod)
plot(x,y)
#abline(mod)
library(ggplot2)
ggplot(mapping= aes(x, y)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE)


```

## Overall check for assumptions

```{r}
plot(mod)
```

Produces series of graphs (first two are the most important)

### 1st graph: Constancy of variance

```         
        Plot of the residuals against the fitted values
        → Should look like the sky at night
        
```

### 2nd graph: Normality of errors

Normal QQ plot = plot of the ordered residuals against the fitted values → Should be a reasonably straight line

## Linear Model - Assumptions

-   Linear relationship between x and y
-   Independence of residuals
-   Constant variance of residuals
-   Normality: Residuals are normally distributed

## Assumption 1 - Linear Relationship

-   use a scatterplot to check
-   if this assumption is violated we have unrealistic predictions and estimates of the standard deviation
-   How to deal with this? You can transform the variables or alter the model.

```{r}
plot(x,y)
```

## Assumption 2 - Independence of Residuals

-   Plot residuals in time/ observation order / based on observation location / ...
-   You expect that they are equally scattered around 0
-   You can also use the Durban-Watson-Test
-   Autocorrelation can have serious effects on the model
-   You can add an AR correlation term to the model. Sometimes it also helps to add a further covariate.

```{r}
res <- residuals(mod)
plot(x, res)
```

## Durban-Watson-Test

-   H0: There is no correlation among the residuals.

-   HA: The residuals are autocorrelated.

```{r}
library(car)
durbinWatsonTest(mod)
```

-   The p-value is larger than 0.05, so we cannot reject the null hypothesis that there is no correlation between residuals.

## Assumption 3 - Constant variance or errors

-   Plot fitted values vs residuals
-   You expect that they are equally scattered around 0

```{r}
plot(fitted(mod),res)
```

## Assumption 4 - Normality of Residuals

-   Use qq-plot to compare quantiles.
-   Or use the Shapiro-Wilk-Test
-   If you do not find a Normal Distribution, check for outliers or transform your variable.

```{r}
qqPlot(res)
```

## Shapiro-Wilk-Test for Normality

-   H0: The data is normally distributed
-   HA: The data comes from an other distribution

```{r}
shapiro.test(res)
```

-   We cannot reject the null-hypothesis that the data is normally distributed.

## If model doesn’t seem to fit your data:

### Is your response really continuous?

If not another model might be more appropriate: - Continuous: linear model → LM e.g. height, weight - Count: Poisson model → GLM e.g. number of individuals - Binary: Binomial model → GLM e.g. presence / absence

### Are there obvious patterns?

For example many zeros: You could separate in two analysis: Binomial model for success / failure and linear model for successes

### Are there outliers that should be omitted?

4th graph of plot(model): Plot of Cook´s distances versus raw data → Highlights the identity of particularly influential data points

### Relationship not a straight line?

Polynomial regression e.g. a quadratic function might be an option

```{r eval=F}
 lm(y ~ x + I(x^2))
```

### Transformation

You could for example use a log transformation of the response variable

```{r eval=FALSE}
	lm(log(y) ~ x)
```

### Are there other explanatory variables that you should include?

SHOW ON PENGUIN EXAMPLE (include species as categorical variable)

## Definition - Linear Model with multiple predictors

$$\begin{equation}\label{eqn:linearregression}
y_i = \beta_0 + \beta_1x_{1,i} + ... + \beta_px_{p,i} + \epsilon_i, \qquad   i=1,...,n
\end{equation}$$ where $y$ is the dependent variable, $x_1 ... x_p$ are the independent variables (also called explanatory variables), $\beta_0 ... \beta_p$ are the regression coefficients, $\epsilon\sim N(0,\sigma^2)$ is the error coefficient and $p \geq 1$.

## The penguin data set

![](images/penguins.png) Artwork by @allison_horst

Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins/. doi: 10.5281/zenodo.3960218.

::: panel-tabset
### R

<https://allisonhorst.github.io/palmerpenguins/>

```{r}
library(palmerpenguins)
head(penguins)
```

### Python

<https://github.com/mcnakhaee/palmerpenguins?tab=readme-ov-file>

```{python}
from palmerpenguins import load_penguins

penguins = load_penguins()
penguins.head()
```
:::

## Exercise

1.  Using the penguin data set, fit a linear model to determine the relationship between the body mass index and the flipper length.

2.  The flipper length differs accross penguin species. How could you add this to your model?

### Solution

Remove missing values:

```{r}
library(dplyr)
penguins_filtered <- penguins %>%
  filter(complete.cases(.))
```

Fit a linear model:

```{r}

y <- penguins_filtered$body_mass_g
x <- penguins_filtered$flipper_length_mm

mod <- lm(y~x)
summary(mod)
```

Check linear relationship:

```{r}
plot(x,y)
```

Check independence of residuals

```{r}

res <- residuals(mod)
plot(x, res)

library(car)
durbinWatsonTest(mod)
```

Check constant variance or errors

```{r}
plot(fitted(mod),res)
```

Check Normality of Residuals

```{r}
qqPlot(res)
hist(res)

shapiro.test(res)
```

Fit a new model to consider penguin species as well.

```{r}

mod_add <-  lm(penguins_filtered$body_mass_g ~ penguins_filtered$flipper_length_mm + penguins_filtered$species)

mod_spec <- lm(penguins_filtered$body_mass_g ~ penguins_filtered$flipper_length_mm * penguins_filtered$species)

summary(mod_spec)
anova(mod_add, mod_spec)
```

The model with the interaction term between flipper length and species improves the model.

# Plotting

## Standard library

```{r}
# subset data
df.4 <- df[df$hive==4,]
# plot temperature outside
plot(df.4$time, df.4$t_o, ylim=c(0,40),type = 'p', pch=4)
# choose colours
cl <- rainbow(5)
# choose colums
cols <- 4:8
# plot each column
for (i in 1:5){
    lines(df.4$time, df.4[,cols[i]],col = cl[i],type = 'p', pch=4, ylim=c(0,40))
}
# add legend
legend("topright", legend=c(1, 2, 3, 4, 5, "outside"),
       col=c(cl, "black"), pch = 4, lty = 0, cex=0.8)
```

### Points or Lines? (type)

-   “p”: Points
-   “l”: Lines
-   “b”: Both

### Line type (lty)

![http://www.sthda.com/english/wiki/line-types-in-r-lty](images/linetypes.png)

Source: <http://www.sthda.com/english/wiki/line-types-in-r-lty> \### Point types (pch) ![http://www.sthda.com/english/wiki/r-plot-pch-symbols-the-different-point-shapes-available-in-r](images/dottypes.png)

Source: <http://www.sthda.com/english/wiki/r-plot-pch-symbols-the-different-point-shapes-available-in-r>

## ggplot

```{r}
# subset data
df.4 <- df[df$hive==4,]
# choose columns
df.4.cols <- df.4[,c(1,4:9)]
# reshape data
library(reshape)
mdf <- melt(df.4.cols, id=c("time")) 
# plot data
library(ggplot2)
ggplot(data = mdf, aes(x=time, y=value)) + geom_line(aes(colour=variable)) + ylim(c(0, 40))
```

## Exercises - Plotting and more

::: panel-tabset
### R

```{r eval = F}


## Plotting

# 1. Choose a set of data from your background. 
# Decide for one of the presented plotting-libraries.
# Create a plot and add a title and custom x and y labels.
# In case you plotted multiple lines, add a legend.
# Difficult: Try to find out, how you can change the fontsize of the axis-labels.

# 2. Automatically save your plot to a given destination  

# 3. Try to make your code more abstract and useful. 
# Put your code within a function.
# - use the file-name (destination) as a parameter
# - In case you have multiple covariate, 
# use the covariate(s) to be plotted as input parameter
# - In case it makes sense to subset your data, introduce
#    a parameter for the choice of the subset.

# Always have in mind: if something goes wrong, you can use debugging.

# Exercises - Piping

# 1. Rewrite the following code using %>% and %<>%:

x <- 2
round(log(x))


# 2. Rewrite the second line of following code:

x <- rnorm(10,100)
round(sum(sqrt(x)), 3)


## Loops and functions again
# If you have some code you wrote in the past 
# for some exercise, for your studies, for your work...
# See if you can find pieces of code which you 
# just copied and pasted multiple times (don't worry, this is normal)
# Try to transform the code using loops and functions

```

### Python

### R - Solutions

```{r eval= FALSE}
## Exercises - Piping

# 1. Rewrite the following code using %>% and %<>%:

x <- 2
round(log(x))


x <- 2
x %<>% log %>% round

# 2. Rewrite the second line of following code:

x <- rnorm(10,100)
round(sum(sqrt(x)), 3)



x %>% sqrt %>% sum %>% round(3)

## Plotting

# 1. Choose a set of data from your background. 
# Decide for one of the presented plotting-libraries.
# Create a plot and add a title and custom x and y labels.
# In case you plotted multiple lines, add a legend.
# Try to find out, how you can change the fontsize of the axis-labels.

# 2. Automatically save your plot to a given destination  

# 3. Try to make your code more abstract and useful. 
# Put your code within a function.
# - use the file-name (destination) as a parameter
# - In case you have multiple covariate, 
# use the covariate(s) to be plotted as input parameter
# - In case it makes sense to subset your data, introduce
#    a parameter for the choice of the subset.

# Always have in mind: if something goes wrong, you can use debugging.

## Loops and functions again
# If you have some code you wrote in the past 
# for some exercise, for your studies, for your work...
# See if you can find pieces of code which you 
# just copied and pasted multiple times (don't worry, this is normal)
# Try to transform the code using loops and functions

```
:::

# Markdown and R-Markdown

Markdown is a great way to document your code and to write reports about your results. Here, we describe R-Markdown in detail. However, you can also use python. Especially easy to work with are jupyter notebooks, which can switch the formatting of individual cells between code and markdown. See this [documentation](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) for details.

## Output formats

The three most common output options for R-Markdown are html, pdf and word documents. If you want to create pdf documents, tex needs to be installed.

![](images/rmarkdown.jpeg)

Depending on your choice, your document will have a different output parameter in the header:

```{r eval=F}
# html
---
title: "R Markdown Example"
author: "Somebody"
date: "August 14, 2019"
output: html_document
---
```

```{r eval=F}

# word
---
title: "R Markdown Example"
author: "Somebody"
date: "August 14, 2019"
output: word_document
---

```

There are many formatting options which you can specify in the header. This might be useful options for html:

```{r eval=F}

---
title: "R Markdown Example"
author: "Somebody"
date: "August 14, 2019"
output: 
  html_document:
    toc: true # print a table of content
    toc_depth: 2 # maximal depth of the table of content
    number_sections: true # automatically number the sections
    code_folding: hide # have buttons to show/ hide code
    theme: united # specify a theme
    toc_float: true # generate a navigation bar

---
```

## Document structure

If you create a new R-Markdown document, R will automatically create a sample document. You can see that “#” can be used to create headers:

```{r eval=F}
# Header 1

## Header 2

### Header 3
```

## Code blocks

For code blocks you have many options, too. The two most important are:

-   eval: If set to true, the code will be executed
-   echo: If set to true, the output will be printed/ plotted

## Lists

```{r eval=F}
* unordered list
    + sub-item 1
    + sub-item 2
        - sub-sub-item 1
* item 2

    
1. ordered list
2. item 2
    i) sub-item 1

```

-   unordered list
    -   sub-item 1
    -   sub-item 2
        -   sub-sub-item 1
-   item 2

1.  ordered list
2.  item 2
    i)  sub-item 1

## Insert an image

```{r eval=F}
![Some description](path to image)
```

## Further documentation

A good documentation of R-Markdown can be found here: <https://bookdown.org/yihui/rmarkdown/>

And here is a cheat sheet: <https://www.rstudio.com/resources/cheatsheets/#rmarkdown>

There is a lot more you can do with R-Markdown, see: <https://rmarkdown.rstudio.com/gallery.html>

# Assignment

-   you all get a confirmation of participation
-   you can submit a small assignment for 1 CP

## Assignment

-   you can choose if you want to use R or Python
-   Create a markdown document
-   Choose a dataset from PANGEA
-   Think about the following question: What do you want fo find out? What is the motivation for your analysis?
-   Choose 5 of the following tasks. You can also come up with own ideas.
-   Write a short text for each task explaining what you have been doing

## Ideas

-   Make some exploratory analysis:
    -   print the mean/ median/ standard deviation for each column
    -   print the total number of missing values
    -   print the number of missing values for each column
-   Transform some of the columns/ Create new columns based on existing ones
-   Create a subset of your data
-   Exclude all rows with missing values
-   Create a plot
-   Write a function that takes a filename and some additional parameters. The function should create a plot and save it as “png” with that filename
-   Create a linear model

## Send us an e-mail

-   If you want to do an assignment, please send us an e-mail:

-   "I want to do an assignment.""

-   "I do not want a grade on my certificate. / I want to have a grade on my certificate./ I want to have a grade if it is better than \<1.3, 1.7, 2.0, 2.3, 2.7, 3.0, ...\>"

# Short statistical breaks

## Dinosours

<https://www.autodeskresearch.com/publications/samestats>

## Correlation

<https://www.tylervigen.com/spurious-correlations>

## Beginners Book

<https://devhumor.com/content/uploads/images/July2020/Best-Programming-Book-for-Beginners-Comic---Art-of-Searching-on-Google.png>

<!-- # Linear Model -->

<!-- sub <- df[df$t_o<50 & df$t_o>-10,] -->

<!-- plot(sub$h, sub$t_o) -->

<!-- mod <-lm(sub$h~ sub$t_o) -->

<!-- summary(mod) -->

<!-- wir, kolja, micha und ralf -->
